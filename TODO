IMPLEMENTATION AND FEATURES
--------------------------------------------------------------------------------
Legend
[ ]		not started
[L]		works, but some limitations (noted with feature)
[C]		complete

Updated 2011-11-12

Assembly Runtime
================
	[ ] convert the assembly code into a library that the sinks link against,
		instead of compiling the code directly into them

	[C] design assembly interface
	[L] implement framework
		[C] starting runtime does self-discovery
		[C] node adds self to participants
		[C] start assembly composition

	- shared memory library
		[C] "libregistration" - now obsolete
		[C] multi-process-aware
		[C] multi-threading-aware
		[C] self-contained library
		[C] verify with multiple simultaneous members joining/leaving
		[ ] verify with one multi-threaded member making/destroying regions
		[ ] change shmgrp to use message queues for registering with a group instead
			of inotify. redesign that communication substrate, in fact...

	[C] support multiple fat binaries

	- distributed assembly (Alex)
		[C] assembly RPC thread
		[ ] [support executing apps on nodes w/o GPUs]
		[C] implement separation of local/remote assembly interfaces
		[ ] add use of monitoring API to assembly composition
		[L] duplicate register calls across nodes in assembly
			i think the algorithm is broken

	- remote data paths (Alex w/ network API)
		[ ] what is local:remote sink process configuration?

	[ ] incorporate notion of groups in assemblies, for MPI apps (Alex)

	[L] multi-threaded backend processes (Alex)
		(not tested with a multi-threaded app)
		[ ] need to perform scheduling, and to support multi-threaded apps

	[ ] scheduling interface (Dipanjan)

Monitoring
==========
	[C] Design data structure(s) for exporting Lynx data (Naila)
	[C] glue Lynx and local monitor with MQs (Naila)
	[C] push Lynx data from local->global monitor (Alex + Magda)
	[C] design API to access all of monitoring data (Naila + Alex)
	[ ] build library code to expose this API (Alex + Naila)
	[ ] glue global monitor and library with shmgrp (Alex + Naila)
	[ ] Assembly can add a Lynx instrumentor pattern to implement during the
		import/export protocol. State will need to be added somewhere, and
		configured before the export happens.

Build Environment
=================
	[C] remove build dependences of backend/ on interposer/ etc
		[C] move pack/unpack functions outside of interposer/
	[ ] perhaps create an SConstruct for each machine this may be built on
		instead of having globals inside one file

Other details
=============
	[C]	registered variables (the symbols) are assumed at the moment to be
		memory addresses; the runtime says they may also be strings: remove this
		assumption
			libci.c : cudaMemcpy[To|From]Symbol
			localsink.c : nv_exec_pkt
	[C] move cuda_app/ to test/
	[ ] enable the interposer to void using assemblies, and simply instrument
		what an application is doing
			- e.g. what calls are made and what are their arguments?
		This would be useful to determine various characteristics of the
		application:
			- how much memory does it allocate?
			- how frequently does it move data and how large are the chunks?
			- how frequently does it call into the API?
			- etc


KNOWN BUGS
==========
	[ ] Executing multiple processes on same node (returning the same assembly
		configurations) is not entirely safe somewhere. runtime complains
		about not being able to send a signal to the localsink, and upon exit
		some assemblies apparently still exist
			update: localsink assumes one app at a time, make a list instead

	[C] remotesink experiences a segfault executing binomialOptions when it
		calls __cudaUnregisterFatBinary
			fix: remote thread kept invoking do_cuda_rpc on the previous packet
			(unregister) even when the remote application terminated; now
			maintain a reference count on remote end

	[ ] segv in runtime when Ctrl+c'ing it after a node exits uncleanly (SIGKILL)

	[ ] BUG seems to not be used correctly everywhere.

	[ ] provide a means for safe failure if the application performs setDevice
		on an ID that doesn't exist.

	[ ] provide more robust runtime, for cleaning up all sinks, even when the
		application segfaults (runtime will need to monitor)

POTENTIAL BUGS
==============

	[ ] Executing the same application process on different nodes, mapping 1+
	vgpus to the same remote node. CUDA state registration functions may be
	initializing similar state (function, variable, cubin names, etc). If that's
	true, we'll need to make the remote end (remotesink.c) multi-process...
